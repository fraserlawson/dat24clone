{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: machine learning practice with scikit-learn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use datasets about wine.\n",
    "\n",
    "There are two datasets; one for white wines, one for red wines.\n",
    "\n",
    "For information about the dataset look here:\n",
    "\n",
    "- [https://archive.ics.uci.edu/ml/datasets/wine+quality](https://archive.ics.uci.edu/ml/datasets/wine+quality)\n",
    "- [Data description](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names)\n",
    "\n",
    "# Part 1: Regression\n",
    "\n",
    "We will focus on **white wines only** for this part.\n",
    "\n",
    "We will attempt to predict white wine (perceived) **quality** using information about the wine.\n",
    "\n",
    "#### 1: Read in the white wine data and perform exploratory data analysis on it. Be sure to look for things like:\n",
    "\n",
    "- missing values\n",
    "- strange values\n",
    "- relationships between features and the target (quality)\n",
    "\n",
    "If you have trouble reading the file in, a good idea is to open it in a simple text editor to investigate its formatting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Do a train-test split and choose 3 predictors to predict quality\n",
    "\n",
    "Remember: we want to avoid testing on the final test set until the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Now do *another* train-test split using the training set above.\n",
    "\n",
    "We do this to simulate a train-test split so we can evaluate a model, **without** touching the test set we created in step 2.\n",
    "\n",
    "We often call this second test set (the one it's OK to test on) the \"validation\" set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Fit a linear regression on the training set and examine your interecept and coefficients. What do they tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: How well does your model do? Calculate the RMSE on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5: Obtain the average RMSE score across 10 folds of cross-validation. This should give you a better idea of your model's performance on new data. How does it compare to the RMSE calculated above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6: Now try using *all the features* with both a lasso and ridge regression. Obtain the best alpha values using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7: What are your conclusions based on the models you've fit above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8: Bonus - compare your findings to another regression model\n",
    "\n",
    "Use the same 3 features you chose above, and try one of: KNN, a decision tree, a random forest, or something completely different!\n",
    "\n",
    "**8.1:** first, get the cross-validated RMSE of your other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2:** now, test both models on your **test** set (which you shouldn't have touched until now!) and compare the two models' \"real world\" performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
