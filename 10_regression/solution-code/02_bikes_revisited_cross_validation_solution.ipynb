{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Linear Regression: Further Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will build on the bikes dataset we used last time, this time with more \"best practice\".\n",
    "\n",
    "Read in the bikes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bikes = pd.read_csv(\"../assets/data/bikeshare.csv\")\n",
    "bikes.rename(columns={\"count\": \"total_rentals\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Choose 3 features to predict `total_rentals` and put them in variables X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = bikes[[\"temp\", \"windspeed\", \"holiday\"]]\n",
    "y = bikes[\"total_rentals\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Create a training and test set\n",
    "\n",
    "We'll be using the training set for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Measure the performance of your model across 7 folds\n",
    "\n",
    "Get a feel for your model's performance. Try both RMSE (using `'neg_mean_squared_error'`) and Mean Absolute Error (MAE) using `'neg_mean_absolute_error'` as scoring metrics and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 165.98840264655772\tAverage MAE: 126.5131019365265\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "mse_scores = cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=7)\n",
    "mae_scores = cross_val_score(model, X_train, y_train, scoring=\"neg_mean_absolute_error\", cv=7)\n",
    "\n",
    "avg_rmse = np.mean(np.sqrt(-mse_scores))\n",
    "avg_mae = np.mean(-mae_scores)\n",
    "\n",
    "print(f\"Average RMSE: {avg_rmse}\\tAverage MAE: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: We'll try two more models\n",
    "\n",
    "First, do a new train-test split on the entire bikes data.\n",
    "\n",
    "Previously, we only used 3 features for our split, but we want access to all of them now, so we can train different models that use different combinations of features.\n",
    "\n",
    "We will do both our cross-validated training and model evaluation on our **training** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bikes.drop(\"total_rentals\", axis=1),\n",
    "                                                    bikes[\"total_rentals\"],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try **two** more models with different combinations of features and compare their performance.\n",
    "\n",
    "*As bonus practice, you could put the code you've written so far into a function so you can easily try different combinations of features!*\n",
    "\n",
    "*For example, it could take as parameters a feature matrix X (your training set) and y (your training targets) and a list of columns to use for the model, and could print/return the cross-validated scores.*\n",
    "\n",
    "```python\n",
    "def evaluate_features(features, X, y):\n",
    "    ...```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMS for ['humidity', 'holiday'] across 7 folds:\t172.0394358437882\n",
      "Average RMS for ['humidity', 'holiday', 'atemp'] across 7 folds:\t158.36817203339197\n"
     ]
    }
   ],
   "source": [
    "def evaluate_features(features, X, y, k=7):\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    X_local = X[features]\n",
    "\n",
    "    mse_scores = cross_val_score(model, X_local, y, scoring=\"neg_mean_squared_error\", cv=k)\n",
    "    \n",
    "    avg_rmse = np.mean(np.sqrt(-mse_scores))\n",
    "    \n",
    "    print(f\"Average RMS for {features} across {k} folds:\\t{avg_rmse}\")\n",
    "\n",
    "evaluate_features([\"humidity\", \"holiday\"], X_train, y_train)\n",
    "evaluate_features([\"humidity\", \"holiday\", \"atemp\"], X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5: Take the best of your three trained models and evaluate it on the *test* set.\n",
    "\n",
    "This is to get an estimate of how well your model performs in the real world. It would be your final reported accuracy score. After this step, you should **not** train-test on the same data anymore, because you will be prone to overfitting.\n",
    "\n",
    "For this question, first use your best model to predict values on the test inputs (X_test) and compare to the actual values (y_test).\n",
    "\n",
    "(*Note: if you have a model object from step 4, but used `cross_val_score` to evaluate performance, you will need to fit the model again because `cross_val_score` doesn't do this for you.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.2316178502663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "humidity_holiday_atemp_model = LinearRegression().fit(X_train[[\"humidity\", \"holiday\", \"atemp\"]], y_train)\n",
    "\n",
    "y_pred = humidity_holiday_atemp_model.predict(X_test[[\"humidity\", \"holiday\", \"atemp\"]])\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6: How did your model do?\n",
    "\n",
    "If your test set error is similar to the training/cross-validated error, it means your training accuracy was representative of the model's real world performance.\n",
    "\n",
    "Overfitting happens when your test error is much higher than your training error - i.e. your model hasn't generalised.\n",
    "\n",
    "Look at the output from **5** - how well did your model do \"in the real world\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set error is very similar to the cross-validated error, which means the model performs just as well \"in the real world\", outside of the training phase, as it did during training.\n",
    "\n",
    "This is a good sign that it's a stable model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
