{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Word2Vec & Doc2Vec\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Word2Vec is another unsupervised model for latent variable NLP.\n",
    "\n",
    "It was originally released by Google and further refined at Stanford.\n",
    "\n",
    "This model creates word vectors, multidimensional representations of words.  \n",
    "\n",
    "- *assembly → [0.12315, 0.23425, 0.89745324, 0.235234, 0.234234, …]* \n",
    "\n",
    "This is similar to having a distribution of concepts or topics that the word may come from.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"assets/images/vector_2.png\" style=\"width:100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"assets/images/vector_1.png\" style=\"width:100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Comparing two vectors (e.g., using cosine similarity) estimates how similar the two words are. However, the notion of relatedness depends on what vector representation you have chosen for the words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have four (tiny) documents:\n",
    "- Document 1 : “seattle seahawks jerseys”\n",
    "- Document 2 : “seattle seahawks highlights”\n",
    "- Document 3 : “denver broncos jerseys”\n",
    "- Document 4 : “denver broncos highlights”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we use word context vectors:\n",
    "\n",
    "<img src=\"assets/images/word_context_1.png\" style=\"width:100%\" />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we use document occurrence vectors:\n",
    "\n",
    "<img src=\"assets/images/doc_occur_1.png\" style=\"width:100%\" />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The vectors we have been discussing so far are very high-dimensional (thousands, or even millions) and sparse.\n",
    "But there are techniques to learn lower-dimensional dense vectors for words using the same intuitions.\n",
    "\n",
    "These dense vectors are called embeddings. We use pre-trained word embedding models.\n",
    "\n",
    "<img src=\"assets/images/embeddings_1.png\" style=\"width:40%\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What do we use Word2Vec for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With a trained model, Word2Vec can be used for many tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- man is to woman as king is to        ?\n",
    "- good is to best as smart is to        ?\n",
    "- china is to beijing as russia is to        ?\n",
    "\n",
    "Turns out the word-context based vector model we just learnt is good for such analogy tasks:\n",
    "\n",
    "                -[king] – [man] + [woman] ≈ [queen]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A commonly used feature of Word2Vec is being able to ask what words are similar to each other.\n",
    "\n",
    "For example, if you ask for words similar to ‘france’, you would get:\n",
    "    \n",
    "<img src=\"assets/images/word2vec_sim_1.png\" style=\"width:100%\" /> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we have data for other languages, Word2Vec could also be used for translation.\n",
    "\n",
    "<img src=\"assets/images/word2vec_sim_2.png\" style=\"width:100%\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can apply the same principle to documents rather than for words: the goal of `doc2vec` is to create a numeric representation of a document, regardless of it’s length.\n",
    "\n",
    "The `doc2vec` models may be used in the following way: for training, a set of documents is required. a word vector **W** is generated for each word, and a document vector **D** is generated for each document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use `doc2vec` for article similarity comparison.\n",
    "\n",
    "Converting all our articles to vectors, we can use simple trigonometry to find similar content: measuring the difference between the new content & articles in our database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"assets/images/cosine.png\" style=\"width:100%\" /> "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
