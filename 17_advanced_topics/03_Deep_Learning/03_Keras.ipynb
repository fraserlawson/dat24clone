{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "# Keras: Deep Learning library for TensorFlow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ">Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. \n",
    "\n",
    ">It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "ref: https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><a>Install instructions</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Keras can be installed using `pip`:\n",
    "\n",
    "** pip install keras **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2><a>Kaggle Challenge Data</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">The Otto Group is one of the worldâ€™s biggest e-commerce companies, A consistent analysis of the performance of products is crucial. However, due to diverse global infrastructure, many identical products get classified differently.\n",
    "For this competition, we have provided a dataset with 93 features for more than 200,000 products. The objective is to build a predictive model which is able to distinguish between our main product categories. \n",
    "Each row corresponds to a single product. There are a total of 93 numerical features, which represent counts of different events. All features have been obfuscated and will not be defined any further.\n",
    "\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### For this section we will use the Kaggle Otto Group Challenge Data. You will find these data in \n",
    "`assets/data/kaggle_ottogroup/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2><a>Data Preparation</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halloran/anaconda/envs/python36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scripts.kaggle_data import load_data, preprocess_data, preprocess_labels\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 classes\n",
      "93 dims\n"
     ]
    }
   ],
   "source": [
    "X_train, labels = load_data('assets/data/kaggle_ottogroup/train.csv', train=True)\n",
    "X_train, scaler = preprocess_data(X_train)\n",
    "Y_train, encoder = preprocess_labels(labels)\n",
    "\n",
    "X_test, ids = load_data('assets/data/kaggle_ottogroup/test.csv', train=False)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "nb_classes = Y_train.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "dims = X_train.shape[1]\n",
    "print(dims, 'dims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
       "       'Class_7', 'Class_8', 'Class_9'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train  # one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2><a>Using Keras</a></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 dims\n",
      "Building model...\n",
      "9 classes\n",
      "Epoch 1/1\n",
      "61878/61878 [==============================] - 2s 36us/step - loss: 1.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e3947b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = X_train.shape[1]\n",
    "print(dims, 'dims')\n",
    "print(\"Building model...\")\n",
    "\n",
    "nb_classes = Y_train.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(nb_classes, input_shape=(dims,), activation='sigmoid'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Simplicity is pretty impressive right? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now lets understand:\n",
    "<pre>The core data structure of Keras is a <b>model</b>, a way to organize layers. \n",
    "\n",
    "The main type of model is the <b>Sequential</b> model, a linear stack of layers.</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What we did here is stacking a Fully Connected (<b>Dense</b>) layer of trainable weights from the input to the output and an <b>Activation</b> layer on top of the weights layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2><a>(some) others `keras.core.layers`</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* `keras.layers.core.Flatten()`\n",
    "* `keras.layers.core.Reshape(target_shape)`\n",
    "* `keras.layers.core.Permute(dims)`\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# now: model.output_shape == (None, 64, 10)\n",
    "# note: `None` is the batch dimension\n",
    "```\n",
    "\n",
    "* `keras.layers.core.Lambda(function, output_shape=None, arguments=None)`\n",
    "* `keras.layers.core.ActivityRegularization(l1=0.0, l2=0.0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "from keras.layers.core import Activation\n",
    "\n",
    "Activation(activation)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Supported Activations** : [https://keras.io/activations/]\n",
    "\n",
    "**Advanced Activations**: [https://keras.io/layers/advanced-activations/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you need to, you can further configure your optimizer. \n",
    "\n",
    "A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).\n",
    "\n",
    "Here we used <b>SGD</b> (stochastic gradient descent) as an optimization algorithm for our trainable weights.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"http://sebastianruder.com/content/images/2016/09/saddle_point_evaluation_optimizers.gif\" width=\"40%\">\n",
    "\n",
    "Source & Reference: http://sebastianruder.com/content/images/2016/09/saddle_point_evaluation_optimizers.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2><a>\"Data Sciencing\" this example a little bit more</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What we did here is nice, however in the real world it is not useable because of overfitting.\n",
    "Lets try and solve it with cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<img src=\"assets/images/overfitting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To avoid overfitting, we will first split out data to training set and test set and test out model on the test set.\n",
    "Next: we will use two of keras's callbacks <b>EarlyStopping</b> and <b>ModelCheckpoint</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's see first the model we implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 9)                 846       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 846\n",
      "Trainable params: 846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.8672 - val_loss: 1.8577\n",
      "Epoch 2/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.8477 - val_loss: 1.8401\n",
      "Epoch 3/50\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 1.8315 - val_loss: 1.8254\n",
      "Epoch 4/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.8177 - val_loss: 1.8127\n",
      "Epoch 5/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.8057 - val_loss: 1.8016\n",
      "Epoch 6/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7951 - val_loss: 1.7916\n",
      "Epoch 7/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7855 - val_loss: 1.7827\n",
      "Epoch 8/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7769 - val_loss: 1.7745\n",
      "Epoch 9/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7689 - val_loss: 1.7670\n",
      "Epoch 10/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7616 - val_loss: 1.7600\n",
      "Epoch 11/50\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 1.7549 - val_loss: 1.7536\n",
      "Epoch 12/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7485 - val_loss: 1.7476\n",
      "Epoch 13/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7426 - val_loss: 1.7419\n",
      "Epoch 14/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7371 - val_loss: 1.7366\n",
      "Epoch 15/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7319 - val_loss: 1.7316\n",
      "Epoch 16/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7269 - val_loss: 1.7269\n",
      "Epoch 17/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7222 - val_loss: 1.7224\n",
      "Epoch 18/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7178 - val_loss: 1.7181\n",
      "Epoch 19/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7136 - val_loss: 1.7141\n",
      "Epoch 20/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7096 - val_loss: 1.7102\n",
      "Epoch 21/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.7058 - val_loss: 1.7065\n",
      "Epoch 22/50\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 1.7021 - val_loss: 1.7030\n",
      "Epoch 23/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6986 - val_loss: 1.6997\n",
      "Epoch 24/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6953 - val_loss: 1.6965\n",
      "Epoch 25/50\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 1.6921 - val_loss: 1.6934\n",
      "Epoch 26/50\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 1.6891 - val_loss: 1.6905\n",
      "Epoch 27/50\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 1.6862 - val_loss: 1.6877\n",
      "Epoch 28/50\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 1.6834 - val_loss: 1.6850\n",
      "Epoch 29/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6807 - val_loss: 1.6824\n",
      "Epoch 30/50\n",
      "52596/52596 [==============================] - 1s 16us/step - loss: 1.6782 - val_loss: 1.6800\n",
      "Epoch 31/50\n",
      "52596/52596 [==============================] - 1s 19us/step - loss: 1.6758 - val_loss: 1.6776\n",
      "Epoch 32/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6734 - val_loss: 1.6754\n",
      "Epoch 33/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6712 - val_loss: 1.6733\n",
      "Epoch 34/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6690 - val_loss: 1.6712\n",
      "Epoch 35/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6670 - val_loss: 1.6692\n",
      "Epoch 36/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6650 - val_loss: 1.6673\n",
      "Epoch 37/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6631 - val_loss: 1.6655\n",
      "Epoch 38/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6613 - val_loss: 1.6638\n",
      "Epoch 39/50\n",
      "52596/52596 [==============================] - 1s 18us/step - loss: 1.6595 - val_loss: 1.6621\n",
      "Epoch 40/50\n",
      "52596/52596 [==============================] - 1s 17us/step - loss: 1.6578 - val_loss: 1.6605\n",
      "Epoch 41/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6562 - val_loss: 1.6589\n",
      "Epoch 42/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6547 - val_loss: 1.6574\n",
      "Epoch 43/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6532 - val_loss: 1.6559\n",
      "Epoch 44/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6517 - val_loss: 1.6546\n",
      "Epoch 45/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6503 - val_loss: 1.6532\n",
      "Epoch 46/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6489 - val_loss: 1.6519\n",
      "Epoch 47/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6476 - val_loss: 1.6506\n",
      "Epoch 48/50\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 1.6464 - val_loss: 1.6494\n",
      "Epoch 49/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6451 - val_loss: 1.6482\n",
      "Epoch 50/50\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 1.6440 - val_loss: 1.6471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110e48710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "fBestModel = 'assets/data/saved_models/best_model.h5' \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1) \n",
    "best_model = ModelCheckpoint(fBestModel, verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=50, \n",
    "          batch_size=128, verbose=True, callbacks=[best_model, early_stop]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><a>Multi-Layer Fully Connected Networks</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"assets/images/MLP.png\" width=\"45%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Forward and Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"assets/images/backprop.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Q:** _How hard can it be to build a Multi-Layer Fully-Connected Network with keras?_\n",
    "\n",
    "**A:** _It is basically the same, just add more layers!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 100)               9400      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 909       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 10,309\n",
      "Trainable params: 10,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(dims,)))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/20\n",
      "52596/52596 [==============================] - 1s 16us/step - loss: 1.1811 - val_loss: 0.8870\n",
      "Epoch 2/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.8101 - val_loss: 0.7944\n",
      "Epoch 3/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.7526 - val_loss: 0.7582\n",
      "Epoch 4/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.7245 - val_loss: 0.7373\n",
      "Epoch 5/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.7072 - val_loss: 0.7227\n",
      "Epoch 6/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.6948 - val_loss: 0.7120\n",
      "Epoch 7/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.6856 - val_loss: 0.7054\n",
      "Epoch 8/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.6787 - val_loss: 0.6999\n",
      "Epoch 9/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.6732 - val_loss: 0.6939\n",
      "Epoch 10/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6684 - val_loss: 0.6904\n",
      "Epoch 11/20\n",
      "52596/52596 [==============================] - 1s 15us/step - loss: 0.6647 - val_loss: 0.6871\n",
      "Epoch 12/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.6612 - val_loss: 0.6840\n",
      "Epoch 13/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.6584 - val_loss: 0.6837\n",
      "Epoch 14/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.6559 - val_loss: 0.6808\n",
      "Epoch 15/20\n",
      "52596/52596 [==============================] - 1s 17us/step - loss: 0.6537 - val_loss: 0.6779\n",
      "Epoch 16/20\n",
      "52596/52596 [==============================] - 1s 20us/step - loss: 0.6516 - val_loss: 0.6777\n",
      "Epoch 17/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6499 - val_loss: 0.6765\n",
      "Epoch 18/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6485 - val_loss: 0.6748\n",
      "Epoch 19/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6470 - val_loss: 0.6736\n",
      "Epoch 20/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6457 - val_loss: 0.6723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110e34d68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=20, \n",
    "          batch_size=128, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
