{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Principal Components Analysis \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "In this lab, let's try PCA on a dataset derived from the USDA National Nutrient Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the `nutrition_usda` data set and look at the variables **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check for highly correlated features in our dataset. Remove any redundant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used = []\n",
    "corrs = []\n",
    "for i, j in enumerate(df.corr().columns):\n",
    "    for k in range(len(df.corr())):\n",
    "        if ((df.corr().iloc[k, i] > 0.9) & \n",
    "            (j not in used) &\n",
    "            (j != df.corr().index[k])):\n",
    "            \n",
    "            used.append(j)\n",
    "            corrs.append((j, df.corr().index[k], \n",
    "                          np.round(df.corr().iloc[k, i], 2)))\n",
    "\n",
    "            \n",
    "corrsdf = pd.DataFrame([[i[0] for i in corrs],\n",
    "                        [i[1] for i in corrs],\n",
    "                        [i[2] for i in corrs]])\n",
    "\n",
    "corrsdf = corrsdf.T.rename(columns = {0:'column',1:'row',2:'corr'})\n",
    "corrsdf[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Remove redundant features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, separate the non-numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, look at the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.hist(bins=50, xlabelsize=-1, ylabelsize=-1, figsize=(11,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the variables are \"zero\" inflated and skewed right. We may want to consider transformation so \"improve\" the distributions and hopefully produce better correlations for our PCA. \n",
    "\n",
    "Note: this is an optional step that may not always improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "# add 1 because data must be positive (we have many zeros)\n",
    "df = df + 1\n",
    "df_TF = pd.DataFrame(index=df.index)\n",
    "for i in df.columns.values:\n",
    "    df_TF[\"%s_TF\" % i] = boxcox(df.loc[:, i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_TF.hist(bins=50, xlabelsize=-1, ylabelsize=-1, figsize=(11,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should help our PCA.\n",
    "\n",
    "To account for different scales of measurement, we'll standardize to mean=0, variance=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "df_TF = StandardScaler().fit_transform(df_TF)\n",
    "\n",
    "print(\"mean: \", np.round(df_TF.mean(), 2))\n",
    "print(\"standard dev: \", np.round(df_TF.std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the eigenvalues to find most important components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit.explained_variance_ratio_)\n",
    "\n",
    "print(fit.explained_variance_ratio_[:5].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keeping the first 5 eigenvectors, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pd.DataFrame(pca[:, :5], index=df.index)\n",
    "pca = pca.join(df_desc)\n",
    "pca.drop(['CommonName','MfgName','ScientificName'], axis=1, inplace=True)\n",
    "pca.rename(columns={0:'c1',1:'c2',2:'c3',3:'c4',4:'c5'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to interpret the components\n",
    "\n",
    "(this is where deep subject matter expertise, in this case nutrition, comes in handy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Component one** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vects = fit.components_[:5]\n",
    "\n",
    "one = pd.Series(vects[0], index=df.columns)\n",
    "one.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Component two**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two = pd.Series(vects[1], index=df.columns)\n",
    "two.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for #3, 4 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now let's look at which food groups are most common in each component **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Component 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.sort_values(by='c1')['FoodGroup'][:500].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Component 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.sort_values(by='c2')['FoodGroup'][:500].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat for the other three components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
